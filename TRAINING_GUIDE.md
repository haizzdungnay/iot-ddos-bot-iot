# HÆ°á»›ng dáº«n Training Model LSTM cho PhÃ¡t hiá»‡n DDoS

## ğŸ“‹ Má»¥c lá»¥c

1. [Tá»•ng quan](#tá»•ng-quan)
2. [Chuáº©n bá»‹ dá»¯ liá»‡u](#chuáº©n-bá»‹-dá»¯-liá»‡u)
3. [Chiáº¿n lÆ°á»£c Training](#chiáº¿n-lÆ°á»£c-training)
4. [CÃ¡c Config Ä‘Æ°á»£c Ä‘á» xuáº¥t](#cÃ¡c-config-Ä‘Æ°á»£c-Ä‘á»-xuáº¥t)
5. [Quy trÃ¬nh Training](#quy-trÃ¬nh-training)
6. [ÄÃ¡nh giÃ¡ vÃ  Tá»‘i Æ°u](#Ä‘Ã¡nh-giÃ¡-vÃ -tá»‘i-Æ°u)
7. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Tá»•ng quan

Dá»± Ã¡n nÃ y sá»­ dá»¥ng **LSTM (Long Short-Term Memory)** Ä‘á»ƒ phÃ¡t hiá»‡n táº¥n cÃ´ng DDoS trÃªn máº¡ng IoT vá»›i Bot-IoT dataset.

### Äáº·c Ä‘iá»ƒm cá»§a bÃ i toÃ¡n:

- **Loáº¡i**: Binary Classification (Normal vs Attack/DDoS)
- **Dataset**: Bot-IoT (UNSW Canberra)
- **Model**: LSTM / Bidirectional LSTM
- **ThÃ¡ch thá»©c chÃ­nh**: Class imbalance (thÆ°á»ng cÃ³ nhiá»u Normal hÆ¡n Attack)

---

## ğŸ“Š Chuáº©n bá»‹ dá»¯ liá»‡u

### 1. Download Bot-IoT Dataset

Bot-IoT dataset cÃ³ sáºµn trÃªn nhiá»u nguá»“n:

#### **Nguá»“n Khuyáº¿n nghá»‹: Kaggle** â­

**Option A: Bot-IoT Full Dataset**
```bash
# CÃ i Ä‘áº·t Kaggle CLI
pip install kaggle

# Download (cáº§n cáº¥u hÃ¬nh Kaggle API token trÆ°á»›c)
kaggle datasets download -d vigneshvenkateswaran/bot-iot -p data/raw/ --unzip
```
- Link: [https://www.kaggle.com/datasets/vigneshvenkateswaran/bot-iot](https://www.kaggle.com/datasets/vigneshvenkateswaran/bot-iot)
- KÃ­ch thÆ°á»›c: ~16GB (full)

**Option B: Bot-IoT 5% Sample** (Nháº¹ hÆ¡n, khuyáº¿n nghá»‹ cho test)
```bash
kaggle datasets download -d vigneshvenkateswaran/bot-iot-5-data -p data/raw/ --unzip
```
- Link: [https://www.kaggle.com/datasets/vigneshvenkateswaran/bot-iot-5-data](https://www.kaggle.com/datasets/vigneshvenkateswaran/bot-iot-5-data)
- KÃ­ch thÆ°á»›c: ~800MB

**Download thá»§ cÃ´ng tá»« Kaggle:**
1. Truy cáº­p link trÃªn
2. ÄÄƒng nháº­p Kaggle (miá»…n phÃ­)
3. Click "Download"
4. Giáº£i nÃ©n vÃ o `data/raw/`

#### **Nguá»“n thay tháº¿:**

- **CIC IoT-DIAD 2024**: [https://www.unb.ca/cic/datasets/iot-diad-2024.html](https://www.unb.ca/cic/datasets/iot-diad-2024.html)
- **CICIoT2023**: [https://www.unb.ca/cic/datasets/iotdataset-2023.html](https://www.unb.ca/cic/datasets/iotdataset-2023.html)
- **IoT-DH Dataset**: [https://data.mendeley.com/datasets/8dns3xbckv/1](https://data.mendeley.com/datasets/8dns3xbckv/1)

### 2. Äáº·t dá»¯ liá»‡u vÃ o thÆ° má»¥c

```bash
# Náº¿u file cÃ³ tÃªn khÃ¡c, Ä‘á»•i tÃªn:
mv data/raw/UNSW_2018_IoT_Botnet_Dataset*.csv data/raw/bot_iot.csv

# Hoáº·c dÃ¹ng trá»±c tiáº¿p vá»›i --data flag:
python src/train_lstm.py --config default --data data/raw/UNSW_2018_IoT_Botnet_Dataset_5.csv
```

### 3. Kiá»ƒm tra dá»¯ liá»‡u

Dá»¯ liá»‡u Bot-IoT cáº§n cÃ³:
- **Cá»™t nhÃ£n**: ThÆ°á»ng lÃ  `attack`, `category`, hoáº·c tÆ°Æ¡ng tá»±
  - GiÃ¡ trá»‹: "Normal", "DDoS", "DoS", v.v.
- **Cá»™t features**: CÃ¡c Ä‘áº·c trÆ°ng máº¡ng (flow duration, packet size, protocol, v.v.)

**LÆ°u Ã½**: Náº¿u tÃªn cá»™t nhÃ£n khÃ¡c, cáº§n chá»‰nh trong `config.py` â†’ `DataConfig.label_column`

---

## ğŸ“ Chiáº¿n lÆ°á»£c Training

### 1. Xá»­ lÃ½ Class Imbalance

Bot-IoT thÆ°á»ng cÃ³ **imbalance** giá»¯a Normal vÃ  Attack. CÃ³ 3 cÃ¡ch xá»­ lÃ½:

#### **CÃ¡ch 1: Class Weights (Äá» xuáº¥t)**
- Tá»± Ä‘á»™ng tÃ­nh trá»ng sá»‘ cho tá»«ng class
- KhÃ´ng tÄƒng kÃ­ch thÆ°á»›c dataset
- **Khi nÃ o dÃ¹ng**: Máº·c Ä‘á»‹nh, phÃ¹ há»£p vá»›i háº§u háº¿t trÆ°á»ng há»£p

```python
# Trong config.py
use_class_weight = True
use_smote = False
```

#### **CÃ¡ch 2: SMOTE (Synthetic Minority Over-sampling)**
- Táº¡o thÃªm dá»¯ liá»‡u synthetic cho class thiá»ƒu sá»‘
- TÄƒng kÃ­ch thÆ°á»›c training set
- **Khi nÃ o dÃ¹ng**: Class imbalance ráº¥t náº·ng (tá»· lá»‡ > 1:10)

```python
# Trong config.py
use_class_weight = False
use_smote = True
```

#### **CÃ¡ch 3: KhÃ´ng xá»­ lÃ½**
- Chá»‰ dÃ¹ng khi data Ä‘Ã£ balanced
- **Khi nÃ o dÃ¹ng**: Sau khi Ä‘Ã£ undersample/oversample thá»§ cÃ´ng

```python
# Trong config.py
use_class_weight = False
use_smote = False
```

### 2. Chá»n kiáº¿n trÃºc LSTM

#### **Stateless LSTM (time_steps=1)**
- Má»—i máº«u lÃ  1 network flow Ä‘á»™c láº­p
- **Æ¯u Ä‘iá»ƒm**: ÄÆ¡n giáº£n, nhanh, phÃ¹ há»£p vá»›i Bot-IoT
- **NhÆ°á»£c Ä‘iá»ƒm**: KhÃ´ng khai thÃ¡c temporal dependency

```python
# Trong config.py
time_steps = 1
```

#### **Sequence LSTM (time_steps>1)**
- NhÃ³m nhiá»u flows liÃªn tiáº¿p thÃ nh sequence
- **Æ¯u Ä‘iá»ƒm**: Khai thÃ¡c temporal patterns
- **NhÆ°á»£c Ä‘iá»ƒm**: Cáº§n nhiá»u data hÆ¡n, phá»©c táº¡p hÆ¡n

```python
# Trong config.py
time_steps = 10  # VÃ­ dá»¥: 10 flows liÃªn tiáº¿p
```

**Khuyáº¿n nghá»‹**: Báº¯t Ä‘áº§u vá»›i `time_steps=1`, sau Ä‘Ã³ thá»­ nghiá»‡m vá»›i sequence náº¿u cáº§n.

### 3. Hyperparameters chÃ­nh

| Parameter | Ã nghÄ©a | GiÃ¡ trá»‹ Ä‘á» xuáº¥t |
|-----------|---------|-----------------|
| `lstm_units` | Sá»‘ units trong LSTM layer | 64 (default), 32 (light), 128 (deep) |
| `dropout_rate` | Tá»· lá»‡ dropout (chá»‘ng overfit) | 0.3 - 0.4 |
| `dense_units` | Sá»‘ units trong Dense layer | 32 (default), 16 (light), 64 (deep) |
| `learning_rate` | Learning rate cho Adam optimizer | 1e-3 (0.001) |
| `batch_size` | Batch size | 256 - 512 |
| `epochs` | Sá»‘ epochs tá»‘i Ä‘a | 50 - 100 |
| `early_stopping_patience` | Patience cho early stopping | 10 - 15 |

---

## âš™ï¸ CÃ¡c Config Ä‘Æ°á»£c Ä‘á» xuáº¥t

Dá»± Ã¡n cung cáº¥p 4 config cÃ³ sáºµn:

### 1. **Default Config** (Khuyáº¿n nghá»‹ báº¯t Ä‘áº§u)

```python
# Cháº¡y vá»›i:
python src/train_lstm.py --config default

# Hoáº·c trong code:
from train_lstm import train_model
model, history, metrics = train_model(config_name='default')
```

**Äáº·c Ä‘iá»ƒm**:
- LSTM units: 64
- Dense units: 32
- Dropout: 0.3
- Epochs: 50
- Batch size: 256
- Class weight: True

**Khi nÃ o dÃ¹ng**: Báº¯t Ä‘áº§u experiment, baseline model

### 2. **Lightweight Config** (Nhanh, nháº¹)

```python
python src/train_lstm.py --config lightweight
```

**Äáº·c Ä‘iá»ƒm**:
- LSTM units: 32 (giáº£m)
- Dense units: 16 (giáº£m)
- Batch size: 512 (tÄƒng)
- Epochs: 20 (giáº£m)

**Khi nÃ o dÃ¹ng**:
- Testing pipeline nhanh
- Dataset nhá»
- TÃ i nguyÃªn háº¡n cháº¿

### 3. **Deep Config** (Model sÃ¢u hÆ¡n)

```python
python src/train_lstm.py --config deep
```

**Äáº·c Ä‘iá»ƒm**:
- LSTM units: 128 (tÄƒng)
- Dense units: 64 (tÄƒng)
- Dropout: 0.4 (tÄƒng)
- Epochs: 100 (tÄƒng)
- Early stopping patience: 15

**Khi nÃ o dÃ¹ng**:
- Dataset lá»›n (>100K samples)
- Muá»‘n maximize performance
- CÃ³ GPU máº¡nh

### 4. **Sequence Config** (Sequence LSTM)

```python
python src/train_lstm.py --config sequence
```

**Äáº·c Ä‘iá»ƒm**:
- Time steps: 10 (sá»­ dá»¥ng sequence)
- LSTM units: 128
- Epochs: 100
- Sá»­ dá»¥ng Bidirectional LSTM

**Khi nÃ o dÃ¹ng**:
- Data cÃ³ temporal dependency
- Muá»‘n thá»­ nghiá»‡m sequence modeling
- **LÆ°u Ã½**: Cáº§n xá»­ lÃ½ data khÃ¡c (group flows theo time)

---

## ğŸš€ Quy trÃ¬nh Training

### BÆ°á»›c 1: CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Táº¡o virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# hoáº·c .venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº·t file Bot-IoT CSV vÃ o `data/raw/bot_iot.csv`

### BÆ°á»›c 3: Cháº¡y training

#### **Option 1: Command line (Äá» xuáº¥t)**

```bash
# Training vá»›i default config
python src/train_lstm.py --config default --data data/raw/bot_iot.csv

# Hoáº·c vá»›i config khÃ¡c
python src/train_lstm.py --config lightweight --data data/raw/bot_iot.csv
```

#### **Option 2: Jupyter Notebook**

```bash
jupyter notebook notebooks/demo_training.ipynb
```

Má»Ÿ notebook vÃ  cháº¡y tá»«ng cell theo thá»© tá»±.

#### **Option 3: Python script**

```python
from train_lstm import train_model

# Train
model, history, metrics = train_model(
    config_name='default',
    data_path='data/raw/bot_iot.csv'
)
```

### BÆ°á»›c 4: Monitor training

#### **TensorBoard**

```bash
# Má»Ÿ TensorBoard Ä‘á»ƒ theo dÃµi real-time
tensorboard --logdir logs/
```

Truy cáº­p: http://localhost:6006

#### **Output trong console**

Training sáº½ hiá»ƒn thá»‹:
- Progress bar tá»«ng epoch
- Loss, accuracy, precision, recall
- Validation metrics
- Early stopping notifications

### BÆ°á»›c 5: ÄÃ¡nh giÃ¡ káº¿t quáº£

Sau khi training, cÃ¡c file sáº½ Ä‘Æ°á»£c táº¡o:

```
models/
  â”œâ”€â”€ lstm_ddos_model.h5      # Model Ä‘Ã£ train
  â”œâ”€â”€ scaler.pkl              # StandardScaler
  â””â”€â”€ feature_cols.pkl        # Danh sÃ¡ch features

results/
  â”œâ”€â”€ training_history.json   # Lá»‹ch sá»­ training
  â””â”€â”€ metrics.json            # Metrics Ä‘Ã¡nh giÃ¡

logs/
  â””â”€â”€ <timestamp>/            # TensorBoard logs
```

#### ÄÃ¡nh giÃ¡ chi tiáº¿t:

```bash
python src/evaluate.py \
    --model models/lstm_ddos_model.h5 \
    --data data/processed/bot_iot_preprocessed.csv \
    --output results/
```

Káº¿t quáº£:
```
results/
  â”œâ”€â”€ confusion_matrix.png
  â”œâ”€â”€ roc_curve.png
  â”œâ”€â”€ pr_curve.png
  â”œâ”€â”€ training_history.png
  â””â”€â”€ evaluation_metrics.json
```

---

## ğŸ“ˆ ÄÃ¡nh giÃ¡ vÃ  Tá»‘i Æ°u

### 1. Metrics quan trá»ng

#### **Confusion Matrix**
```
                Predicted
              Normal  Attack
Actual Normal   TN      FP
       Attack   FN      TP
```

- **True Negative (TN)**: Normal Ä‘Æ°á»£c phÃ¡t hiá»‡n Ä‘Ãºng
- **False Positive (FP)**: Normal bá»‹ nháº§m thÃ nh Attack (False Alarm)
- **False Negative (FN)**: Attack bá»‹ bá» sÃ³t (Nguy hiá»ƒm!)
- **True Positive (TP)**: Attack Ä‘Æ°á»£c phÃ¡t hiá»‡n Ä‘Ãºng

#### **Chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡**

| Metric | CÃ´ng thá»©c | Ã nghÄ©a | Má»¥c tiÃªu |
|--------|-----------|---------|----------|
| **Accuracy** | (TP+TN)/(TP+TN+FP+FN) | Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng tá»•ng thá»ƒ | >95% |
| **Precision** | TP/(TP+FP) | Trong cÃ¡c máº«u dá»± Ä‘oÃ¡n Attack, bao nhiÃªu Ä‘Ãºng? | >90% |
| **Recall** | TP/(TP+FN) | Trong cÃ¡c Attack tháº­t, phÃ¡t hiá»‡n Ä‘Æ°á»£c bao nhiÃªu? | **>95%** (quan trá»ng nháº¥t) |
| **F1-Score** | 2Ã—(PrecisionÃ—Recall)/(Precision+Recall) | CÃ¢n báº±ng giá»¯a Precision vÃ  Recall | >92% |
| **ROC AUC** | Area Under ROC Curve | Kháº£ nÄƒng phÃ¢n biá»‡t 2 class | >0.95 |

**LÆ°u Ã½**: Vá»›i DDoS detection, **Recall** (detect Ä‘Æ°á»£c bao nhiÃªu attack) quan trá»ng hÆ¡n Precision (giáº£m false alarm).

### 2. PhÃ¢n tÃ­ch káº¿t quáº£

#### **TrÆ°á»ng há»£p 1: High Accuracy, Low Recall**
- **NguyÃªn nhÃ¢n**: Model bias vá» class Normal
- **Giáº£i phÃ¡p**:
  - TÄƒng class weight cho Attack
  - Sá»­ dá»¥ng SMOTE
  - Äiá»u chá»‰nh threshold (tá»« 0.5 â†’ 0.3)

#### **TrÆ°á»ng há»£p 2: Overfitting (train acc >> val acc)**
- **NguyÃªn nhÃ¢n**: Model há»c thuá»™c training data
- **Giáº£i phÃ¡p**:
  - TÄƒng dropout rate (0.3 â†’ 0.4 - 0.5)
  - Giáº£m sá»‘ LSTM units
  - ThÃªm regularization (L2)
  - TÄƒng training data

#### **TrÆ°á»ng há»£p 3: Underfitting (train acc tháº¥p)**
- **NguyÃªn nhÃ¢n**: Model quÃ¡ Ä‘Æ¡n giáº£n
- **Giáº£i phÃ¡p**:
  - TÄƒng sá»‘ LSTM units (64 â†’ 128)
  - ThÃªm LSTM layers
  - Giáº£m dropout
  - Train lÃ¢u hÆ¡n

### 3. Hyperparameter Tuning

#### **Grid Search thá»§ cÃ´ng**

Thá»­ nghiá»‡m cÃ¡c káº¿t há»£p:

```python
# Experiment 1: Baseline
lstm_units=64, dropout=0.3, lr=1e-3

# Experiment 2: Deeper
lstm_units=128, dropout=0.4, lr=1e-3

# Experiment 3: Lower LR
lstm_units=64, dropout=0.3, lr=5e-4

# Experiment 4: Larger batch
lstm_units=64, dropout=0.3, batch_size=512
```

Ghi láº¡i káº¿t quáº£ vÃ  so sÃ¡nh.

#### **Learning Rate Schedule**

Náº¿u loss khÃ´ng giáº£m:
- Giáº£m learning rate: `1e-3 â†’ 5e-4 â†’ 1e-4`
- Hoáº·c dÃ¹ng ReduceLROnPlateau (Ä‘Ã£ tÃ­ch há»£p sáºµn)

---

## ğŸ”§ Troubleshooting

### âŒ Lá»—i: "FileNotFoundError: data/raw/bot_iot.csv"

**Giáº£i phÃ¡p**:
```bash
# Kiá»ƒm tra Ä‘Æ°á»ng dáº«n
ls data/raw/

# Náº¿u file khÃ´ng tá»“n táº¡i, download Bot-IoT dataset
# Sau Ä‘Ã³ Ä‘áº·t vÃ o data/raw/
```

### âŒ Lá»—i: "KeyError: 'attack'"

**NguyÃªn nhÃ¢n**: TÃªn cá»™t nhÃ£n khÃ´ng Ä‘Ãºng

**Giáº£i phÃ¡p**:
```python
# Kiá»ƒm tra tÃªn cá»™t trong dataset
import pandas as pd
df = pd.read_csv('data/raw/bot_iot.csv')
print(df.columns)

# Chá»‰nh trong src/config.py
label_column = "tÃªn_cá»™t_nhÃ£n_Ä‘Ãºng"
```

### âŒ Model khÃ´ng há»c (loss khÃ´ng giáº£m)

**Kiá»ƒm tra**:
1. Data cÃ³ bá»‹ lá»—i khÃ´ng? (NaN, inf)
2. Features Ä‘Ã£ Ä‘Æ°á»£c normalize chÆ°a? (StandardScaler)
3. Learning rate cÃ³ quÃ¡ cao khÃ´ng?

**Giáº£i phÃ¡p**:
```python
# Giáº£m learning rate
learning_rate = 1e-4  # thay vÃ¬ 1e-3

# Hoáº·c thá»­ optimizer khÃ¡c
optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9)
```

### âŒ Out of Memory (OOM)

**Giáº£i phÃ¡p**:
```python
# Giáº£m batch size
batch_size = 128  # hoáº·c 64

# Hoáº·c giáº£m model size
lstm_units = 32
dense_units = 16
```

### âŒ Training quÃ¡ cháº­m

**TÄƒng tá»‘c**:
1. Giáº£m sá»‘ epochs
2. TÄƒng batch size
3. Sá»­ dá»¥ng GPU (náº¿u cÃ³)
4. Giáº£m kÃ­ch thÆ°á»›c model (dÃ¹ng lightweight config)

---

## ğŸ“ Best Practices

### 1. Quy trÃ¬nh thá»­ nghiá»‡m

```
1. Quick test vá»›i lightweight config (kiá»ƒm tra pipeline)
2. Baseline vá»›i default config
3. Thá»­ nghiá»‡m cÃ¡c config khÃ¡c (deep, sequence)
4. Hyperparameter tuning
5. Chá»n model tá»‘t nháº¥t dá»±a trÃªn validation metrics
6. ÄÃ¡nh giÃ¡ trÃªn test set
```

### 2. Logging vÃ  Tracking

- **Ghi láº¡i má»i experiment**: config, metrics, training time
- **Sá»­ dá»¥ng TensorBoard**: monitor real-time
- **Version control**: commit code sau má»—i experiment thÃ nh cÃ´ng

### 3. Reproducibility

```python
# Set random seed
random_state = 42

# Trong config.py
random_state: int = 42

# Trong numpy, tensorflow
np.random.seed(42)
tf.random.set_seed(42)
```

---

## ğŸ¯ Káº¿t luáº­n vÃ  Khuyáº¿n nghá»‹

### Quy trÃ¬nh Ä‘á» xuáº¥t:

1. **Báº¯t Ä‘áº§u**: `default` config vá»›i `class_weight=True`
2. **Náº¿u recall tháº¥p**: Thá»­ `SMOTE=True` hoáº·c Ä‘iá»u chá»‰nh threshold
3. **Náº¿u muá»‘n tá»‘c Ä‘á»™**: DÃ¹ng `lightweight` config
4. **Náº¿u muá»‘n performance cao**: DÃ¹ng `deep` config
5. **Náº¿u cÃ³ temporal data**: Thá»­ `sequence` config

### Metrics má»¥c tiÃªu:

- **Accuracy**: â‰¥ 95%
- **Precision**: â‰¥ 90%
- **Recall**: â‰¥ 95% (quan trá»ng nháº¥t)
- **F1-Score**: â‰¥ 92%
- **ROC AUC**: â‰¥ 0.95

### Next Steps:

- Thá»­ nghiá»‡m cÃ¡c kiáº¿n trÃºc khÃ¡c (stacked LSTM, attention mechanism)
- Feature engineering (chá»n features quan trá»ng)
- Ensemble methods (káº¿t há»£p nhiá»u models)
- Deploy model thÃ nh API/service

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- Bot-IoT Dataset: https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/
- LSTM: https://colah.github.io/posts/2015-08-Understanding-LSTMs/
- TensorFlow/Keras: https://www.tensorflow.org/guide/keras
- Imbalanced Learning: https://imbalanced-learn.org/

---

**Good luck vá»›i training! ğŸš€**
